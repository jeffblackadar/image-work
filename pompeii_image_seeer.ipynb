{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pompeii_image_seeer.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffblackadar/image_work/blob/master/pompeii_image_seeer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxXEeUHqz33o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']=''\n",
        "os.environ['COMPUTER_VISION_ENDPOINT']='https://image-object-detection.cognitiveservices.azure.com/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-S0_2KBq3txi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade azure-cognitiveservices-vision-computervision"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiMhMG-Dz4mP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://docs.microsoft.com/en-us/azure/cognitive-services/computer-vision/quickstarts-sdk/python-sdk\n",
        "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
        "from azure.cognitiveservices.vision.computervision.models import TextOperationStatusCodes\n",
        "from azure.cognitiveservices.vision.computervision.models import TextRecognitionMode\n",
        "from azure.cognitiveservices.vision.computervision.models import VisualFeatureTypes\n",
        "from msrest.authentication import CognitiveServicesCredentials\n",
        "\n",
        "from array import array\n",
        "import os\n",
        "from PIL import Image\n",
        "import sys\n",
        "import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2-XeDxx309x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add your Computer Vision subscription key to your environment variables.\n",
        "if 'COMPUTER_VISION_SUBSCRIPTION_KEY' in os.environ:\n",
        "    subscription_key = os.environ['COMPUTER_VISION_SUBSCRIPTION_KEY']\n",
        "else:\n",
        "    print(\"\\nSet the COMPUTER_VISION_SUBSCRIPTION_KEY environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
        "    sys.exit()\n",
        "# Add your Computer Vision endpoint to your environment variables.\n",
        "if 'COMPUTER_VISION_ENDPOINT' in os.environ:\n",
        "    endpoint = os.environ['COMPUTER_VISION_ENDPOINT']\n",
        "else:\n",
        "    print(\"\\nSet the COMPUTER_VISION_ENDPOINT environment variable.\\n**Restart your shell or IDE for changes to take effect.**\")\n",
        "    sys.exit()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B7RmGZkWBsUU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "computervision_client = ComputerVisionClient(endpoint, CognitiveServicesCredentials(subscription_key))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pKQeqfJPCBBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "remote_image_url = \"https://pompeiiinpictures.com/pompeiiinpictures/R5/5%2002%2015_files/image003.jpg\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acwktMGjCUSe",
        "colab_type": "code",
        "outputId": "80f83506-8e73-438d-e84b-ddd476261a77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "'''\n",
        "Describe an Image - remote\n",
        "This example describes the contents of an image with the confidence score.\n",
        "'''\n",
        "print(\"===== Describe an image - remote =====\")\n",
        "# Call API\n",
        "description_results = computervision_client.describe_image(remote_image_url )\n",
        "\n",
        "# Get the captions (descriptions) from the response, with confidence level\n",
        "print(\"Description of remote image: \")\n",
        "if (len(description_results.captions) == 0):\n",
        "    print(\"No description detected.\")\n",
        "else:\n",
        "    for caption in description_results.captions:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(caption.text, caption.confidence * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Describe an image - remote =====\n",
            "Description of remote image: \n",
            "'a stone building that has a bench in front of a brick wall' with confidence 62.24%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlqjEsOhCmuE",
        "colab_type": "code",
        "outputId": "a4035e1e-23b8-474c-a571-ac30e0f9ce4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "'''\n",
        "Categorize an Image - remote\n",
        "This example extracts (general) categories from a remote image with a confidence score.\n",
        "'''\n",
        "print(\"===== Categorize an image - remote =====\")\n",
        "# Select the visual feature(s) you want.\n",
        "remote_image_features = [\"categories\"]\n",
        "# Call API with URL and features\n",
        "categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
        "\n",
        "# Print results with confidence score\n",
        "print(\"Categories from remote image: \")\n",
        "if (len(categorize_results_remote.categories) == 0):\n",
        "    print(\"No categories detected.\")\n",
        "else:\n",
        "    for category in categorize_results_remote.categories:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(category.name, category.score * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Categorize an image - remote =====\n",
            "Categories from remote image: \n",
            "'outdoor_stonerock' with confidence 53.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxB8R9b2CtMN",
        "colab_type": "code",
        "outputId": "8f867c86-6d56-4941-9a0d-3c89965f407c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "'''\n",
        "Tag an Image - remote\n",
        "This example returns a tag (key word) for each thing in the image.\n",
        "'''\n",
        "print(\"===== Tag an image - remote =====\")\n",
        "# Call API with remote image\n",
        "tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
        "\n",
        "# Print results with confidence score\n",
        "print(\"Tags in the remote image: \")\n",
        "if (len(tags_result_remote.tags) == 0):\n",
        "    print(\"No tags detected.\")\n",
        "else:\n",
        "    for tag in tags_result_remote.tags:\n",
        "        print(\"'{}' with confidence {:.2f}%\".format(tag.name, tag.confidence * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Tag an image - remote =====\n",
            "Tags in the remote image: \n",
            "'stone' with confidence 99.21%\n",
            "'rock' with confidence 99.07%\n",
            "'building' with confidence 99.00%\n",
            "'outdoor' with confidence 98.60%\n",
            "'brick' with confidence 92.56%\n",
            "'ruin' with confidence 82.91%\n",
            "'ruins' with confidence 76.29%\n",
            "'old' with confidence 63.80%\n",
            "'sky' with confidence 54.32%\n",
            "'concrete' with confidence 45.09%\n",
            "'building material' with confidence 43.49%\n",
            "'cement' with confidence 19.17%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9HfXY7bC6x4",
        "colab_type": "code",
        "outputId": "b21b1bf4-522c-4f6e-bd82-7af9db775c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "'''\n",
        "Detect Objects - remote\n",
        "This example detects different kinds of objects with bounding boxes in a remote image.\n",
        "'''\n",
        "print(\"===== Detect Objects - remote =====\")\n",
        "# Get URL image with different objects\n",
        "remote_image_url_objects = \"https://raw.githubusercontent.com/Azure-Samples/cognitive-services-sample-data-files/master/ComputerVision/Images/objects.jpg\"\n",
        "# Call API with URL\n",
        "detect_objects_results_remote = computervision_client.detect_objects(remote_image_url_objects)\n",
        "\n",
        "# Print detected objects results with bounding boxes\n",
        "print(\"Detecting objects in remote image:\")\n",
        "if len(detect_objects_results_remote.objects) == 0:\n",
        "    print(\"No objects detected.\")\n",
        "else:\n",
        "    for object in detect_objects_results_remote.objects:\n",
        "        print(\"object at location {}, {}, {}, {}\".format( \\\n",
        "        object.rectangle.x, object.rectangle.x + object.rectangle.w, \\\n",
        "        object.rectangle.y, object.rectangle.y + object.rectangle.h))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Detect Objects - remote =====\n",
            "Detecting objects in remote image:\n",
            "object at location 213, 365, 85, 208\n",
            "object at location 218, 402, 179, 384\n",
            "object at location 238, 417, 298, 416\n",
            "object at location 116, 419, 60, 386\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKFM3D6DD5G-",
        "colab_type": "code",
        "outputId": "a671fc49-8ca5-409d-88c4-86b59f0d6980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Call API with content type (landmarks) and URL\n",
        "detect_domain_results_landmarks = computervision_client.analyze_image_by_domain(\"landmarks\", remote_image_url)\n",
        "print()\n",
        "\n",
        "print(\"Landmarks in the remote image:\")\n",
        "if len(detect_domain_results_landmarks.result[\"landmarks\"]) == 0:\n",
        "    print(\"No landmarks detected.\")\n",
        "else:\n",
        "    for landmark in detect_domain_results_landmarks.result[\"landmarks\"]:\n",
        "        print(landmark[\"name\"])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Landmarks in the remote image:\n",
            "No landmarks detected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2L30F3ED_-q",
        "colab_type": "code",
        "outputId": "bfd461b4-cf0e-49d3-caf4-f7c73c712b6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "'''\n",
        "Detect Color - remote\n",
        "This example detects the different aspects of its color scheme in a remote image.\n",
        "'''\n",
        "print(\"===== Detect Color - remote =====\")\n",
        "# Select the feature(s) you want\n",
        "remote_image_features = [\"color\"]\n",
        "# Call API with URL and features\n",
        "detect_color_results_remote = computervision_client.analyze_image(remote_image_url, remote_image_features)\n",
        "\n",
        "# Print results of color scheme\n",
        "print(\"Getting color scheme of the remote image: \")\n",
        "print(\"Is black and white: {}\".format(detect_color_results_remote.color.is_bw_img))\n",
        "print(\"Accent color: {}\".format(detect_color_results_remote.color.accent_color))\n",
        "print(\"Dominant background color: {}\".format(detect_color_results_remote.color.dominant_color_background))\n",
        "print(\"Dominant foreground color: {}\".format(detect_color_results_remote.color.dominant_color_foreground))\n",
        "print(\"Dominant colors: {}\".format(detect_color_results_remote.color.dominant_colors))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "===== Detect Color - remote =====\n",
            "Getting color scheme of the remote image: \n",
            "Is black and white: False\n",
            "Accent color: 2866A3\n",
            "Dominant background color: Grey\n",
            "Dominant foreground color: Grey\n",
            "Dominant colors: ['Grey']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOrg7OEdIfEC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "66016eb9-1a3b-491e-8047-2f1d8c0d889e"
      },
      "source": [
        "!pip install imutils"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: imutils in /usr/local/lib/python3.6/dist-packages (0.5.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dXk3esDIkA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils import paths\n",
        "import argparse\n",
        "import time\n",
        "import sys\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "# hashing with OpenCV and PythonPython\n",
        "def dhash(image, hashSize=8):\n",
        "    # resize the input image, adding a single column (width) so we\n",
        "    # can compute the horizontal gradient\n",
        "    resized = cv2.resize(image, (hashSize + 1, hashSize))\n",
        "\n",
        "    # compute the (relative) horizontal gradient between adjacent\n",
        "    # column pixels\n",
        "    diff = resized[:, 1:] > resized[:, :-1]\n",
        "\n",
        "    # convert the difference image to a hash\n",
        "    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])\n",
        "\n",
        "def dhash(image, hashSize=8):\n",
        "    # resize the input image, adding a single column (width) so we\n",
        "    # can compute the horizontal gradient\n",
        "    resized = cv2.resize(image, (hashSize + 1, hashSize))\n",
        " \n",
        "    # compute the (relative) horizontal gradient between adjacent\n",
        "    # column pixels\n",
        "    diff = resized[:, 1:] > resized[:, :-1]\n",
        " \n",
        "    # convert the difference image to a hash\n",
        "    return sum([2 ** i for (i, v) in enumerate(diff.flatten()) if v])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71q5CqfUMkJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "700bd5a2-896e-4953-8e76-df843814520d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLRLupHjNwNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from pathlib import Path\n",
        "base_dir = '/content/drive/My Drive/pompeiiinpictures'\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import requests\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n",
        "\n",
        "# Open the coin_models spreadsheet\n",
        "sh = gc.open('pompeii_in_pictures_tbl_webpage_images')\n",
        "worksheet_webpage_images = sh.worksheet(title=\"webpage_images\")\n",
        "worksheet_config = sh.worksheet(title=\"config\")\n",
        "\n",
        "#worksheet_config.update_cell(1, 2, str(2))\n",
        "\n",
        "number_of_models_to_run = 80\n",
        "for number_of_models_to_run_count in range (0,number_of_models_to_run):\n",
        "    model_row = int(worksheet_config.cell(1, 2).value)\n",
        "    #id\tid_webpage\tfolder\timg_src\timg_alt\timg_height\timg_width\n",
        "    img_folder = worksheet_webpage_images.cell(model_row, 3).value #, 'folder')\n",
        "    img_src = worksheet_webpage_images.cell(model_row, 4).value #, 'img_src')\n",
        "    if(img_folder==\"\"):\n",
        "        img_url = \"https://pompeiiinpictures.com/pompeiiinpictures\"+\"/\"+img_src  \n",
        "    else:\n",
        "        img_url = \"https://pompeiiinpictures.com\"+img_folder+\"/\"+img_src\n",
        "    print(str(model_row)+\"-\"+img_url)\n",
        "    worksheet_webpage_images.update_cell(model_row,8,img_url)\n",
        "    remote_image_url = img_url\n",
        "\n",
        "\n",
        "    # load the image for the image has later.  Load it now because it takes a bit of time\n",
        "    img_local_path = img_url.replace(\"https://pompeiiinpictures.com/pompeiiinpictures\",\"\")\n",
        "    img_local_path = img_local_path.replace(\"%20\",\" \")\n",
        "    img_local_path=base_dir+img_local_path\n",
        "    print(img_local_path)\n",
        "    img_file_name = img_local_path[img_local_path.rfind('/')+1:]\n",
        "    img_local_folder = img_local_path[:img_local_path.rfind('/')]\n",
        "\n",
        "    #see if the image is there already\n",
        "    if not os.path.exists(img_local_path):\n",
        "        img_file_name = img_local_path[img_local_path.rfind('/')+1:]\n",
        "        img_local_folder = img_local_path[:img_local_path.rfind('/')]\n",
        "        \n",
        "        if not os.path.exists(img_local_folder):\n",
        "            #os.mkdir(img_local_folder)\n",
        "            path = Path(img_local_folder)\n",
        "            path.mkdir(parents=True,exist_ok=True)\n",
        "        print(img_local_folder+'/'+ img_file_name)    \n",
        "        with open(img_local_folder+'/'+ img_file_name, 'wb') as handle:\n",
        "            response = requests.get(img_url, stream=True)\n",
        "\n",
        "            if not response.ok:\n",
        "                print(response)\n",
        "\n",
        "            for block in response.iter_content(1024):\n",
        "                if not block:\n",
        "                    break\n",
        "\n",
        "                handle.write(block) \n",
        "\n",
        "\n",
        "    # *************************\n",
        "    # Describe image\n",
        "    # *************************\n",
        "\n",
        "    '''\n",
        "    Describe an Image - remote\n",
        "    This example describes the contents of an image with the confidence score.\n",
        "    '''\n",
        "    \n",
        "    # Call API\n",
        "    description_results = computervision_client.describe_image(remote_image_url )\n",
        "\n",
        "    # Get the captions (descriptions) from the response, with confidence level\n",
        "\n",
        "    if (len(description_results.captions) == 0):\n",
        "        azure_img_desc = \"No description detected.\"\n",
        "        azure_img_desc_confidence = \"\"\n",
        "    else:\n",
        "        for caption in description_results.captions:\n",
        "            azure_img_desc = caption.text\n",
        "            azure_img_desc_confidence = caption.confidence * 100\n",
        "\n",
        "    worksheet_webpage_images.update_cell(model_row,9,azure_img_desc)\n",
        "    worksheet_webpage_images.update_cell(model_row,10,azure_img_desc_confidence)\n",
        "    # *************************\n",
        "    # *************************\n",
        "    # Categorize image\n",
        "    # *************************\n",
        "    '''\n",
        "    Categorize an Image - remote\n",
        "    This example extracts (general) categories from a remote image with a confidence score.\n",
        "    '''\n",
        "\n",
        "    # Select the visual feature(s) you want.\n",
        "    remote_image_features = [\"categories\"]\n",
        "    # Call API with URL and features\n",
        "    categorize_results_remote = computervision_client.analyze_image(remote_image_url , remote_image_features)\n",
        "\n",
        "    # Print results with confidence score\n",
        "    azure_img_categories=\"\"\n",
        "    azure_img_categories_score=\"\"\n",
        "\n",
        "    if (len(categorize_results_remote.categories) == 0):\n",
        "        azure_img_categories=\"No categories detected.\"\n",
        "        azure_img_categories_score=\"\"\n",
        "    else:\n",
        "        for category in categorize_results_remote.categories:\n",
        "\n",
        "\n",
        "            azure_img_categories=azure_img_categories+\"[\"+category.name+\"] \"\n",
        "            azure_img_categories_score=azure_img_categories_score+\"[\"+str(category.score * 100)+\"] \"\n",
        "\n",
        "    worksheet_webpage_images.update_cell(model_row,11,azure_img_categories)\n",
        "    worksheet_webpage_images.update_cell(model_row,12,azure_img_categories_score)  \n",
        "    # *************************\n",
        "    # Tag image\n",
        "    # *************************\n",
        "    '''\n",
        "    Tag an Image - remote\n",
        "    This example returns a tag (key word) for each thing in the image.\n",
        "    '''\n",
        "\n",
        "    # Call API with remote image\n",
        "    tags_result_remote = computervision_client.tag_image(remote_image_url )\n",
        "\n",
        "    # Print results with confidence score\n",
        "    azure_img_tags=\"\"\n",
        "    azure_img_tags_confidence=\"\"\n",
        "    if (len(tags_result_remote.tags) == 0):\n",
        "        azure_img_tags=\"No tags detected.\"\n",
        "        azure_img_tags_confidence=\"\"\n",
        "    else:\n",
        "        for tag in tags_result_remote.tags:\n",
        "            azure_img_tags=azure_img_tags+\"[\"+tag.name+\"] \"\n",
        "            azure_img_tags_confidence=azure_img_tags_confidence+\"[\"+str(tag.confidence * 100)+\"] \"\n",
        "\n",
        "    worksheet_webpage_images.update_cell(model_row,13,azure_img_tags)\n",
        "    worksheet_webpage_images.update_cell(model_row,14,azure_img_tags_confidence)        \n",
        "    # *************************\n",
        "\n",
        "    #image hash\n",
        "    if not os.path.exists(img_local_path):\n",
        "        print(\"Error image not loaded for image hash   \" + img_local_path)\n",
        "    else:         \n",
        "        # load the image from disk\n",
        "        path = Path(img_local_folder)\n",
        "        os.chdir(path)\n",
        "        hash_image = cv2.imread(img_file_name)\n",
        " \n",
        "\t      # if the image is None then we could not load it from disk (so\n",
        "\t      # skip it)\n",
        "        if not hash_image is None:\n",
        "            # convert the image to grayscale and compute the hash\n",
        "            hash_image = cv2.cvtColor(hash_image, cv2.COLOR_BGR2GRAY)\n",
        "            imageHash = dhash(hash_image)\n",
        "            worksheet_webpage_images.update_cell(model_row,15,imageHash)\n",
        "        else:\n",
        "            worksheet_webpage_images.update_cell(model_row,15,0)             \n",
        "                         \n",
        "    # *************************\n",
        "    worksheet_config.update_cell(1, 2, str(model_row+1)) \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}