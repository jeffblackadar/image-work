{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Categorized E-II and G-VI-v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jeffblackadar/image_work/blob/master/Categorized_E_II_and_G_VI_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIDuxVewloe",
        "colab_type": "code",
        "outputId": "a9f48aea-55ec-4d1a-f135-b456899a6bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQe1saoFxDYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://github.com/spmallick/learnopencv/blob/master/KerasCNN-CIFAR/keras-cnn-cifar10.ipynb\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, InputLayer\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnXt3MarxV9J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Thanks to\n",
        "# https://thispointer.com/python-how-to-get-list-of-files-in-directory-and-sub-directories/\n",
        "def getListOfFiles(dirName):\n",
        "    import os\n",
        "    # create a list of file and sub directories \n",
        "    # names in the given directory \n",
        "    listOfFile = os.listdir(dirName)\n",
        "    allFiles = list()\n",
        "    # Iterate over all the entries\n",
        "    for entry in listOfFile:\n",
        "        # Create full path\n",
        "        fullPath = os.path.join(dirName, entry)\n",
        "        if os.path.isdir(fullPath):\n",
        "            #allFiles = allFiles + getListOfFiles(fullPath)\n",
        "            print(fullPath)\n",
        "        else:\n",
        "            allFiles.append(entry)\n",
        "            #print(entry)    \n",
        "    return allFiles \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BA0cvMoWxyNP",
        "colab_type": "text"
      },
      "source": [
        "# Copy images into train, validation and test directories\n",
        "This only needs to be run once.\n",
        "20 Images training\n",
        "10 validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tR9P6FbxwXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Move images\n",
        "def copy_images(original_dataset_dir, portrait_image_prefix, train_portrait_dir, validation_portrait_dir, test_portrait_dir):\n",
        "    #run it once time for each class of images\n",
        "    import os, shutil\n",
        "\n",
        "    list_of_files = getListOfFiles(original_dataset_dir)\n",
        "    print(len(list_of_files))\n",
        "    # adjust the ranges based on how the images should be split.\n",
        "    # an equal number per class is required.\n",
        "    #train\n",
        "    for i in range(0,20):\n",
        "        src = os.path.join(original_dataset_dir, list_of_files[i])\n",
        "        if os.path.exists(src):\n",
        "            dst = os.path.join(train_portrait_dir, list_of_files[i])\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "    #validation\n",
        "    for i in range(20,30):\n",
        "        src = os.path.join(original_dataset_dir, list_of_files[i])\n",
        "        if os.path.exists(src):\n",
        "            dst = os.path.join(validation_portrait_dir, list_of_files[i])\n",
        "            shutil.copyfile(src, dst)\n",
        "\n",
        "    #test\n",
        "    for i in range(30,40):\n",
        "        src = os.path.join(original_dataset_dir, list_of_files[i])\n",
        "        if os.path.exists(src):\n",
        "            dst = os.path.join(test_portrait_dir, list_of_files[i])\n",
        "            shutil.copyfile(src, dst)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx-HKVwUyFrp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "base_dir = '/content/drive/My Drive/coin-image-processor/portraits'\n",
        "if not os.path.exists(base_dir):\n",
        "    os.mkdir(base_dir)\n",
        "\n",
        "#make each directory for the types of images\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "if not os.path.exists(train_dir):\n",
        "    os.mkdir(train_dir)\n",
        "\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "if not os.path.exists(validation_dir):\n",
        "    os.mkdir(validation_dir)\n",
        "\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "if not os.path.exists(test_dir):\n",
        "    os.mkdir(test_dir)\n",
        "\n",
        "portrait = 'all'\n",
        "\n",
        "#make each sub-directory\n",
        "train_portrait_dir = os.path.join(train_dir, portrait)\n",
        "if not os.path.exists(train_portrait_dir):\n",
        "    os.mkdir(train_portrait_dir)\n",
        "\n",
        "validation_portrait_dir = os.path.join(validation_dir, portrait)\n",
        "if not os.path.exists(validation_portrait_dir):\n",
        "    os.mkdir(validation_portrait_dir)\n",
        "\n",
        "test_portrait_dir = os.path.join(test_dir, portrait)\n",
        "if not os.path.exists(test_portrait_dir):\n",
        "    os.mkdir(test_portrait_dir)\n",
        "    \n",
        "    \n",
        "copy_images('/content/drive/My Drive/coin-image-processor/photos/elizabeth_young', 'eII', train_portrait_dir, validation_portrait_dir, test_portrait_dir)\n",
        "copy_images('/content/drive/My Drive/coin-image-processor/photos/george_vi', 'gvi', train_portrait_dir, validation_portrait_dir, test_portrait_dir)\n",
        "\n",
        "print(train_portrait_dir)\n",
        "print('total training portrait images:', len(os.listdir(train_portrait_dir)))\n",
        "print(validation_portrait_dir)\n",
        "print('total validation portrait images:', len(os.listdir(validation_portrait_dir)))\n",
        "print(test_portrait_dir)\n",
        "print('total test portrait images:', len(os.listdir(test_portrait_dir)))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AgC4QOWjIQ_4",
        "colab_type": "text"
      },
      "source": [
        "Set up Training, Testing, Validation images.\n",
        "one_hot_label them:\n",
        "1,0 = Elizabeth II\n",
        "0,1 = George VI\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjfqQme1yWDQ",
        "colab_type": "code",
        "outputId": "73eac8e0-ef08-41dc-e88e-b25ffe7a645c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#https://blog.francium.tech/build-your-own-image-classifier-with-tensorflow-and-keras-dc147a15e38e\n",
        "  \n",
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from random import shuffle\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "training_dir = \"/content/drive/My Drive/coin-image-processor/portraits/train/all\"\n",
        "test_dir = \"/content/drive/My Drive/coin-image-processor/portraits/test/all\"\n",
        "validation_dir = \"/content/drive/My Drive/coin-image-processor/portraits/validation/all\"\n",
        "\n",
        "#train_data = '/TensorFlow/ImageData/Vehicles/train'\n",
        "#test_data = '/TensorFlow/ImageData/Vehicles/test'\n",
        "train_data = training_dir \n",
        "test_data = test_dir\n",
        "validation_data = validation_dir\n",
        "\n",
        "def one_hot_label(img):\n",
        "    label = img.split('.')[0]\n",
        "    label = label[:3]\n",
        "    if label == 'eII':\n",
        "        ohl = np.array([1,0])\n",
        "    elif label == 'gvi':\n",
        "        ohl = np.array([0,1])\n",
        "    return ohl\n",
        "\n",
        "def train_data_with_label():\n",
        "    train_images = []\n",
        "    for i in tqdm(os.listdir(train_data)):\n",
        "        path = os.path.join(train_data, i)\n",
        "        print(path)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        #plt.imshow(img)\n",
        "        print(one_hot_label(i))\n",
        "        train_images.append([np.array(img), one_hot_label(i)])\n",
        "        shuffle(train_images)\n",
        "    return train_images\n",
        "\n",
        "def test_data_with_label():\n",
        "    test_images = []\n",
        "    for i in tqdm(os.listdir(test_data)):\n",
        "        path = os.path.join(test_data, i)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)        \n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        #plt.imshow(img)\n",
        "        print(one_hot_label(i))\n",
        "        test_images.append([np.array(img), one_hot_label(i)])\n",
        "        #shuffle(test_images)\n",
        "    return test_images\n",
        "\n",
        "def validation_data_with_label():\n",
        "    validation_images = []\n",
        "    for i in tqdm(os.listdir(validation_data)):\n",
        "        path = os.path.join(validation_data, i)\n",
        "        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)        \n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        #plt.imshow(img)\n",
        "        print(one_hot_label(i))\n",
        "        validation_images.append([np.array(img), one_hot_label(i)])\n",
        "        #shuffle(validation_images)\n",
        "    return validation_images\n",
        "  \n",
        "  \n",
        "  \n",
        "training_images = train_data_with_label()\n",
        "testing_images = test_data_with_label()\n",
        "validation_images = validation_data_with_label()\n",
        "tr_img_data = np.array([i[0] for i in training_images]).reshape(-1,128,128,1)\n",
        "tr_lbl_data = np.array([i[1] for i in training_images])\n",
        "tst_img_data = np.array([i[0] for i in testing_images]).reshape(-1,128,128,1)\n",
        "tst_lbl_data = np.array([i[1] for i in testing_images])\n",
        "val_img_data = np.array([i[0] for i in validation_images]).reshape(-1,128,128,1)\n",
        "val_lbl_data = np.array([i[1] for i in validation_images])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 22%|██▎       | 9/40 [00:00<00:00, 80.14it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2900.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2901.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2903.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2906.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2907.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2910.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2911.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2913.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2914.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2916.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2917.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2920.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2923.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2926.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2927.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2930.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 60%|██████    | 24/40 [00:00<00:00, 75.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2931.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2933.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2934.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/eII2936.png\n",
            "[1 0]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3330.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3331.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3340.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3341.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3350.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3351.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3360.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3361.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3370.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3371.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3380.png\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 40/40 [00:00<00:00, 71.23it/s]\n",
            "  0%|          | 0/20 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3381.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3390.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3391.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3400.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3401.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3410.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3411.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3420.png\n",
            "[0 1]\n",
            "/content/drive/My Drive/coin-image-processor/portraits/train/all/gvi3421.png\n",
            "[0 1]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:00<00:00, 75.15it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 80%|████████  | 16/20 [00:00<00:00, 77.60it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[1 0]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 20/20 [00:00<00:00, 74.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tpWgIuty9jB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "#         zoom_range=0.2, # randomly zoom into images\n",
        "#         rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        #width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        #height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        #horizontal_flip=True,  # randomly flip images\n",
        "        #vertical_flip=False)  # randomly flip images\n",
        "\n",
        "\n",
        "    rescale=1./255,\n",
        "    shear_range=0.05,\n",
        "    zoom_range=0.05,\n",
        "    fill_mode = \"nearest\",    \n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttJrLaqtzG6t",
        "colab_type": "code",
        "outputId": "38d9dfb1-fc52-4fd0-8e55-88e1dbeb9b18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def createModel3():\n",
        "    model = Sequential()\n",
        "    \n",
        "    model.add(InputLayer(input_shape=(128,128,1)))\n",
        "    model.add(Conv2D(filters=32,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=5, padding='same'))\n",
        "    \n",
        "    model.add(Conv2D(filters=50,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=5, padding='same'))\n",
        "    \n",
        "    model.add(Conv2D(filters=80,kernel_size=5,strides=1,padding='same', activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=5, padding='same'))\n",
        "    \n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    #number of classes\n",
        "    # 1,0 E-II\n",
        "    # 0,1 G-VI\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "  \n",
        "\n",
        "\n",
        "model2 = createModel3()\n",
        "\n",
        "model2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model2.summary()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 20\n",
        "epochs = 15\n",
        "\n",
        "\n",
        "\n",
        "# datagen.fit(train_data)\n",
        "#it doesn't make sense we mix test and validation\n",
        "\n",
        "# Fit the model on the batches generated by datagen.flow().\n",
        "history2 = model2.fit_generator(datagen.flow(tr_img_data , tr_lbl_data, batch_size=batch_size),\n",
        "                              #steps_per_epoch=int(np.ceil(tr_img_data .shape[0] / float(batch_size))),\n",
        "                              steps_per_epoch=23,\n",
        "                              epochs=epochs,\n",
        "                              validation_data=(val_img_data, val_lbl_data),\n",
        "                              #validation_split=0.3,\n",
        "                              validation_steps=13,\n",
        "                              #shuffle=True,\n",
        "                              workers=4)\n",
        "\n",
        "model2.evaluate(tst_img_data, tst_lbl_data)\n",
        "\n",
        "\n",
        "#fit(self, x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, \n",
        "#validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, \n",
        "#initial_epoch=0, steps_per_epoch=None, validation_steps=None)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_46 (Conv2D)           (None, 128, 128, 32)      832       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling (None, 26, 26, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 26, 26, 50)        40050     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling (None, 6, 6, 50)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 6, 6, 80)          100080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_30 (MaxPooling (None, 2, 2, 80)          0         \n",
            "_________________________________________________________________\n",
            "dropout_33 (Dropout)         (None, 2, 2, 80)          0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 320)               0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 512)               164352    \n",
            "_________________________________________________________________\n",
            "dropout_34 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 1026      \n",
            "=================================================================\n",
            "Total params: 306,340\n",
            "Trainable params: 306,340\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/15\n",
            "23/23 [==============================] - 3s 120ms/step - loss: 0.7151 - acc: 0.6043 - val_loss: 3.3602 - val_acc: 0.7500\n",
            "Epoch 2/15\n",
            "23/23 [==============================] - 1s 51ms/step - loss: 0.6140 - acc: 0.7457 - val_loss: 4.8388 - val_acc: 0.7000\n",
            "Epoch 3/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.5050 - acc: 0.7717 - val_loss: 3.2236 - val_acc: 0.8000\n",
            "Epoch 4/15\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.4304 - acc: 0.8130 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 5/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.3607 - acc: 0.8304 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 6/15\n",
            "23/23 [==============================] - 1s 49ms/step - loss: 0.3050 - acc: 0.8826 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 7/15\n",
            "23/23 [==============================] - 1s 53ms/step - loss: 0.2863 - acc: 0.8717 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "Epoch 8/15\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.2683 - acc: 0.8935 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 9/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.2631 - acc: 0.8935 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "Epoch 10/15\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1968 - acc: 0.9217 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 11/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.2037 - acc: 0.9087 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "Epoch 12/15\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1631 - acc: 0.9283 - val_loss: 1.6118 - val_acc: 0.9000\n",
            "Epoch 13/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.1623 - acc: 0.9413 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "Epoch 14/15\n",
            "23/23 [==============================] - 1s 50ms/step - loss: 0.1727 - acc: 0.9348 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "Epoch 15/15\n",
            "23/23 [==============================] - 1s 52ms/step - loss: 0.1770 - acc: 0.9326 - val_loss: 2.4177 - val_acc: 0.8500\n",
            "20/20 [==============================] - 0s 330us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4.029523849487305, 0.75]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYpQoSPGzXMN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history2.history['loss'],'r',linewidth=3.0)\n",
        "plt.plot(history2.history['val_loss'],'b',linewidth=3.0)\n",
        "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Loss',fontsize=16)\n",
        "plt.title('Loss Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZrPfp3PzfsF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=[8,6])\n",
        "plt.plot(history2.history['acc'],'r',linewidth=3.0)\n",
        "plt.plot(history2.history['val_acc'],'b',linewidth=3.0)\n",
        "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
        "plt.xlabel('Epochs ',fontsize=16)\n",
        "plt.ylabel('Accuracy',fontsize=16)\n",
        "plt.title('Accuracy Curves',fontsize=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBvPEfjmzpOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "import numpy as np\n",
        "\n",
        "#from keras.models import load_model\n",
        "#model_final = load_model('/content/portrait_model.h5')\n",
        "\n",
        "#function that reads image, shows it on screen and makes a prediction\n",
        "\n",
        "\n",
        "def predict_for(img_name):\n",
        "    #load image from file - VGG16 takes (244,244) input\n",
        "    #myimg = load_img(img_name, target_size=(300,300))\n",
        "    myimg = cv2.imread(img_name, cv2.IMREAD_GRAYSCALE)        \n",
        "    myimg = cv2.resize(myimg, (128, 128))\n",
        "    plt.imshow(myimg)\n",
        "    plt.show()\n",
        "\n",
        "    #convert image pixels to array\n",
        "    myimg = img_to_array(myimg)\n",
        "    myimg = np.expand_dims(myimg, axis=0)\n",
        "    # prepare image for the VGG model\n",
        "    #myimg = preprocess_input(myimg)\n",
        "    #predict probability for all 1000 classes\n",
        "    pred=int(model2.predict(myimg)[0][0])\n",
        "    print(model2.predict(myimg))\n",
        "    #print('Prediction for %s: %s'%(img_name, class_names[pred]))\n",
        "\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/portraits/test/george_vi/gvi3490.png')\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/portraits/test/george_vi/gvi3491.png')\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/portraits/test/george_vi/gvi3500.png')\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/portraits/test/george_vi/gvi3511.png')\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/photos/george_vi/gvi3330.png')\n",
        "predict_for('/content/drive/My Drive/coin-image-processor/photos/elizabeth_young/eII2903.png')\n",
        "#predict_for('/content/drive/My Drive/coin-image-processor/gvi_test_full.jfif')\n",
        "#predict_for('/content/drive/My Drive/coin-image-processor/gvi_test_roughcrop.jpg')\n",
        "#predict_for('/content/drive/My Drive/coin-image-processor/gvi_test_roundcrop.jpg')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}